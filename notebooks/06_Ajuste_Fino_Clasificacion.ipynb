{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNzp9UqNxsAmowD9zLkalzM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "064c7774d93546d8921c9aaad73fecb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_20c0d490e08342dcaf02c9164c5860fd",
              "IPY_MODEL_223f0ff788a14140bcd5faf8198c9c28",
              "IPY_MODEL_7aef343138fc480a959a14ee10e88691"
            ],
            "layout": "IPY_MODEL_4d4ac579d1434f98b0987e6a93b2fb1a"
          }
        },
        "20c0d490e08342dcaf02c9164c5860fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_268c194107a94797b31da806d588fc33",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_9ff81761142a480e9a3fa1a2cd7e16f6",
            "value": "Map:‚Äá100%"
          }
        },
        "223f0ff788a14140bcd5faf8198c9c28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_784cce305db24bf6bbcae70c348059a1",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d0dedd2d2ceb48909105858990387510",
            "value": 1000
          }
        },
        "7aef343138fc480a959a14ee10e88691": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca9ae5a61c634bf3bd3142110d20ec4e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f26434819bd745fab6f5e2eaaac07dad",
            "value": "‚Äá1000/1000‚Äá[00:00&lt;00:00,‚Äá1098.24‚Äáexamples/s]"
          }
        },
        "4d4ac579d1434f98b0987e6a93b2fb1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "268c194107a94797b31da806d588fc33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ff81761142a480e9a3fa1a2cd7e16f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "784cce305db24bf6bbcae70c348059a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0dedd2d2ceb48909105858990387510": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ca9ae5a61c634bf3bd3142110d20ec4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f26434819bd745fab6f5e2eaaac07dad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cbadenes/curso-pln/blob/main/notebooks/06_Ajuste_Fino_Clasificacion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ajuste Fino (Fine-Tuning) para Clasificaci√≥n de Texto\n",
        "Este notebook complementa las diapositivas del curso mostrando un ejemplo pr√°ctico de c√≥mo realizar ajuste fino de un modelo preentrenado para una tarea de clasificaci√≥n de texto.\n"
      ],
      "metadata": {
        "id": "-Qd_tvBYChbg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) Configuraci√≥n del Entorno\n",
        "\n",
        "Primero instalamos las bibliotecas necesarias:"
      ],
      "metadata": {
        "id": "3HmcNg56ClWo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yHxd3GYCejM",
        "outputId": "bb48c419-9904-4cff-9eba-9019ce6e856b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets torch scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importamos las bibliotecas que vamos a utilizar:"
      ],
      "metadata": {
        "id": "ZG0-qNpyCq7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n",
        "from datasets import load_dataset, concatenate_datasets\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "1Yro1YVrCuIV"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) Carga de Datos\n",
        "\n",
        "Para este ejemplo, usaremos el dataset IMDB para an√°lisis de sentimientos, que es p√∫blico y f√°cilmente accesible:\n"
      ],
      "metadata": {
        "id": "IINqlt9mCwb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar ejemplos negativos y positivos por separado\n",
        "negative_examples = load_dataset(\"imdb\", split=\"train[:500]\")  # 500 negativos\n",
        "positive_examples = load_dataset(\"imdb\", split=\"train[12500:13000]\")  # 500 positivos\n",
        "\n",
        "# Combinar los datasets\n",
        "balanced_dataset = concatenate_datasets([negative_examples, positive_examples])\n",
        "\n",
        "# Verificar la distribuci√≥n de clases\n",
        "print(\"\\nDistribuci√≥n de clases en los datos balanceados:\")\n",
        "labels = balanced_dataset['label']\n",
        "unique_labels, counts = np.unique(labels, return_counts=True)\n",
        "for label, count in zip(unique_labels, counts):\n",
        "    print(f\"Clase {label} ({'Negativo' if label == 0 else 'Positivo'}): {count} ejemplos ({count/len(labels)*100:.2f}%)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZFO8vAmC0ce",
        "outputId": "8d703085-f806-40bd-d054-941fb5b8aba7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Distribuci√≥n de clases en los datos balanceados:\n",
            "Clase 0 (Negativo): 500 ejemplos (50.00%)\n",
            "Clase 1 (Positivo): 500 ejemplos (50.00%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) Preparaci√≥n del Modelo Base\n",
        "\n",
        "Utilizaremos un modelo BERT b√°sico como punto de partida:"
      ],
      "metadata": {
        "id": "xEEJjLfBDMlS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos el modelo base y el tokenizer\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SCMWlzADTdW",
        "outputId": "7923b75e-f44d-47c5-b0d4-a0b17023896c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4) Preparaci√≥n de los Datos\n",
        "\n",
        "Tokenizamos los textos y los preparamos para el entrenamiento:"
      ],
      "metadata": {
        "id": "XN29sub_DWXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"],\n",
        "                    padding=\"max_length\",\n",
        "                    truncation=True,\n",
        "                    max_length=512)\n",
        "\n",
        "print(\"\\nTokenizando datos...\")\n",
        "tokenized_dataset = balanced_dataset.map(tokenize_function, batched=True)\n",
        "train_test = tokenized_dataset.train_test_split(test_size=0.2, seed=42, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "064c7774d93546d8921c9aaad73fecb0",
            "20c0d490e08342dcaf02c9164c5860fd",
            "223f0ff788a14140bcd5faf8198c9c28",
            "7aef343138fc480a959a14ee10e88691",
            "4d4ac579d1434f98b0987e6a93b2fb1a",
            "268c194107a94797b31da806d588fc33",
            "9ff81761142a480e9a3fa1a2cd7e16f6",
            "784cce305db24bf6bbcae70c348059a1",
            "d0dedd2d2ceb48909105858990387510",
            "ca9ae5a61c634bf3bd3142110d20ec4e",
            "f26434819bd745fab6f5e2eaaac07dad"
          ]
        },
        "id": "rDADvpzxDarx",
        "outputId": "44d108aa-664b-4d16-a2bf-d9ec6c2d665a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tokenizando datos...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "064c7774d93546d8921c9aaad73fecb0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verificar la distribuci√≥n en los conjuntos de train y test"
      ],
      "metadata": {
        "id": "QVs5ivWRNbSe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nDistribuci√≥n en conjunto de entrenamiento:\")\n",
        "train_labels = train_test[\"train\"]['label']\n",
        "unique_labels, counts = np.unique(train_labels, return_counts=True)\n",
        "for label, count in zip(unique_labels, counts):\n",
        "    print(f\"Clase {label} ({'Negativo' if label == 0 else 'Positivo'}): {count} ejemplos\")\n",
        "\n",
        "print(\"\\nDistribuci√≥n en conjunto de test:\")\n",
        "test_labels = train_test[\"test\"]['label']\n",
        "unique_labels, counts = np.unique(test_labels, return_counts=True)\n",
        "for label, count in zip(unique_labels, counts):\n",
        "    print(f\"Clase {label} ({'Negativo' if label == 0 else 'Positivo'}): {count} ejemplos\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EGsqm1ANcur",
        "outputId": "c2437379-6959-4481-e9f8-479b98201cbb"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Distribuci√≥n en conjunto de entrenamiento:\n",
            "Clase 0 (Negativo): 404 ejemplos\n",
            "Clase 1 (Positivo): 396 ejemplos\n",
            "\n",
            "Distribuci√≥n en conjunto de test:\n",
            "Clase 0 (Negativo): 96 ejemplos\n",
            "Clase 1 (Positivo): 104 ejemplos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5) Configuraci√≥n del Entrenamiento\n",
        "\n",
        "Definimos los par√°metros para el ajuste fino:"
      ],
      "metadata": {
        "id": "R92p7LXqDdZ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=5,                  # Aumentado n√∫mero de √©pocas\n",
        "    per_device_train_batch_size=8,       # Reducido para mejor generalizaci√≥n\n",
        "    per_device_eval_batch_size=8,\n",
        "    weight_decay=0.005,                  # Reducido weight decay\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"steps\",         # Evaluar m√°s frecuentemente\n",
        "    eval_steps=50,                       # Evaluar cada 50 pasos\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=50,\n",
        "    load_best_model_at_end=True,\n",
        "    report_to=\"none\",\n",
        "    learning_rate=5e-5,                  # Aumentado learning rate\n",
        "    warmup_ratio=0.1,                    # A√±adido warmup\n",
        "    gradient_accumulation_steps=4,       # A√±adido gradient accumulation\n",
        "    metric_for_best_model=\"f1\",          # Usar F1 para seleccionar mejor modelo\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4ETR9f6Dgvc",
        "outputId": "84f7e706-7e66-42ed-a37c-f498e9ff403c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definir m√©tricas"
      ],
      "metadata": {
        "id": "ze3fdIzhNnNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }\n"
      ],
      "metadata": {
        "id": "5tDdj3aCNo1T"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6) Entrenamiento del Modelo\n",
        "\n",
        "Realizamos el ajuste fino:"
      ],
      "metadata": {
        "id": "20I8PPdIDjTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nIniciando entrenamiento...\")\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_test[\"train\"],\n",
        "    eval_dataset=train_test[\"test\"],\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "print(\"\\nEntrenando el modelo...\")\n",
        "train_result = trainer.train()\n",
        "print(\"\\nResultados del entrenamiento:\")\n",
        "print(train_result.metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "EUqiqdc0Dmej",
        "outputId": "1cbc6b78-feef-40fd-c28a-009c0dfc5f87"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iniciando entrenamiento...\n",
            "\n",
            "Entrenando el modelo...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [125/125 07:58, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>2.594800</td>\n",
              "      <td>0.545886</td>\n",
              "      <td>0.755000</td>\n",
              "      <td>0.767773</td>\n",
              "      <td>0.757009</td>\n",
              "      <td>0.778846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.341300</td>\n",
              "      <td>0.512044</td>\n",
              "      <td>0.810000</td>\n",
              "      <td>0.802083</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.740385</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Resultados del entrenamiento:\n",
            "{'train_runtime': 481.535, 'train_samples_per_second': 8.307, 'train_steps_per_second': 0.26, 'total_flos': 1052444221440000.0, 'train_loss': 2.774471736907959, 'epoch': 5.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7) Evaluaci√≥n y Uso del Modelo\n",
        "\n",
        "Funci√≥n de predicci√≥n"
      ],
      "metadata": {
        "id": "N2RppKjKD8Dt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(text, threshold=0.6):\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # Preprocesar el texto similar al entrenamiento\n",
        "    inputs = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=256\n",
        "    )\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    # Realizar m√∫ltiples forward passes con dropout activo\n",
        "    model.train()  # Activar dropout\n",
        "    n_forwards = 5\n",
        "    all_probs = []\n",
        "\n",
        "    for _ in range(n_forwards):\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "            all_probs.append(probs)\n",
        "\n",
        "    # Promediar las probabilidades\n",
        "    avg_probs = torch.mean(torch.stack(all_probs), dim=0)\n",
        "    neg_prob = avg_probs[0][0].item()\n",
        "    pos_prob = avg_probs[0][1].item()\n",
        "\n",
        "    print(f\"\\nProbabilidades (promediadas sobre {n_forwards} pases):\")\n",
        "    print(f\"  Negativo: {neg_prob:.4f}\")\n",
        "    print(f\"  Positivo: {pos_prob:.4f}\")\n",
        "\n",
        "    # Usar un umbral m√°s conservador\n",
        "    if pos_prob > threshold:\n",
        "        return \"Positivo\", pos_prob\n",
        "    elif neg_prob > threshold:\n",
        "        return \"Negativo\", neg_prob\n",
        "    else:\n",
        "        # Si no estamos seguros, basarnos en la mayor probabilidad\n",
        "        return \"Positivo\" if pos_prob > neg_prob else \"Negativo\", max(neg_prob, pos_prob)"
      ],
      "metadata": {
        "id": "viEtKW2sNw_5"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Probamos el modelo con algunos ejemplos:"
      ],
      "metadata": {
        "id": "MIwqK8F4NyuX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nProbando el modelo con ejemplos:\")\n",
        "ejemplos = [\n",
        "    \"This movie was absolutely fantastic! Great acting and amazing plot.\",\n",
        "    \"Terrible waste of time. The story made no sense and the acting was awful.\",\n",
        "    \"It was okay, not great but not terrible either. Somewhat entertaining.\"\n",
        "]\n",
        "\n",
        "print(\"\\nPredicciones:\")\n",
        "print(\"-\" * 60)\n",
        "for texto in ejemplos:\n",
        "    print(f\"Texto: {texto}\")\n",
        "    sentiment, conf = predict_sentiment(texto)\n",
        "    print(f\"Predicci√≥n: {sentiment} (Confianza: {conf:.4f})\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "# Verificar algunos ejemplos del dataset\n",
        "print(\"\\nEjemplos del dataset:\")\n",
        "for i in range(5):\n",
        "    print(f\"\\nTexto {i+1}: {balanced_dataset[i]['text'][:200]}...\")\n",
        "    print(f\"Etiqueta: {'Positivo' if balanced_dataset[i]['label'] == 1 else 'Negativo'}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AI_VZnnJD9tG",
        "outputId": "10454db2-9b92-4dae-f56b-cc3dd1cbd876"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Probando el modelo con ejemplos:\n",
            "\n",
            "Predicciones:\n",
            "------------------------------------------------------------\n",
            "Texto: This movie was absolutely fantastic! Great acting and amazing plot.\n",
            "\n",
            "Probabilidades (promediadas sobre 5 pases):\n",
            "  Negativo: 0.0519\n",
            "  Positivo: 0.9481\n",
            "Predicci√≥n: Positivo (Confianza: 0.9481)\n",
            "------------------------------------------------------------\n",
            "Texto: Terrible waste of time. The story made no sense and the acting was awful.\n",
            "\n",
            "Probabilidades (promediadas sobre 5 pases):\n",
            "  Negativo: 0.8970\n",
            "  Positivo: 0.1030\n",
            "Predicci√≥n: Negativo (Confianza: 0.8970)\n",
            "------------------------------------------------------------\n",
            "Texto: It was okay, not great but not terrible either. Somewhat entertaining.\n",
            "\n",
            "Probabilidades (promediadas sobre 5 pases):\n",
            "  Negativo: 0.7457\n",
            "  Positivo: 0.2543\n",
            "Predicci√≥n: Negativo (Confianza: 0.7457)\n",
            "------------------------------------------------------------\n",
            "\n",
            "Ejemplos del dataset:\n",
            "\n",
            "Texto 1: I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ev...\n",
            "Etiqueta: Negativo\n",
            "\n",
            "Texto 2: \"I Am Curious: Yellow\" is a risible and pretentious steaming pile. It doesn't matter what one's political views are because this film can hardly be taken seriously on any level. As for the claim that ...\n",
            "Etiqueta: Negativo\n",
            "\n",
            "Texto 3: If only to avoid making this type of film in the future. This film is interesting as an experiment but tells no cogent story.<br /><br />One might feel virtuous for sitting thru it because it touches ...\n",
            "Etiqueta: Negativo\n",
            "\n",
            "Texto 4: This film was probably inspired by Godard's Masculin, f√©minin and I urge you to see that film instead.<br /><br />The film has two strong elements and those are, (1) the realistic acting (2) the impre...\n",
            "Etiqueta: Negativo\n",
            "\n",
            "Texto 5: Oh, brother...after hearing about this ridiculous film for umpteen years all I can think of is that old Peggy Lee song..<br /><br />\"Is that all there is??\" ...I was just an early teen when this smoke...\n",
            "Etiqueta: Negativo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8) Conclusiones y Notas Importantes\n",
        "\n",
        "En este notebook hemos visto:\n",
        "1. C√≥mo cargar un modelo preentrenado\n",
        "2. C√≥mo preparar datos para ajuste fino\n",
        "3. C√≥mo configurar y realizar el entrenamiento\n",
        "4. C√≥mo evaluar y usar el modelo ajustado\n",
        "\n",
        "Consideraciones importantes:\n",
        "- Este es un ejemplo simplificado para fines did√°cticos\n",
        "- En un caso real, se recomienda:\n",
        "  - Usar m√°s datos de entrenamiento\n",
        "  - Realizar una validaci√≥n cruzada\n",
        "  - Ajustar hiperpar√°metros\n",
        "  - Implementar t√©cnicas de regularizaci√≥n m√°s robustas\n",
        "  - Considerar el balance de clases\n",
        "\n",
        "Para adaptar este c√≥digo a otros problemas de clasificaci√≥n, puedes modificar:\n",
        "- El modelo base (seg√∫n el idioma y dominio)\n",
        "- Los datos de entrenamiento\n",
        "- El n√∫mero de clases (num_labels)\n",
        "- Los hiperpar√°metros de entrenamiento"
      ],
      "metadata": {
        "id": "DgrUSYKdEBZN"
      }
    }
  ]
}