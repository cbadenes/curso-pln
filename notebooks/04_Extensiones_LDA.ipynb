{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cbadenes/curso-pln/blob/main/notebooks/04_Extensiones_LDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebFZnbzaURA9"
      },
      "source": [
        "#1)  Instalaci贸n y dependencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzWAIBHtUOBD",
        "outputId": "94c0c998-3ad6-4165-c450-e7cd90377210"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tomotopy\n",
            "  Downloading tomotopy-0.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (30 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading tomotopy-0.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tomotopy\n",
            "Successfully installed tomotopy-0.13.0\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy==1.26.4 tomotopy==0.13.0 pandas==2.2.2\n",
        "\n",
        "\n",
        "import tomotopy as tp\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-luCInCqUWvA"
      },
      "source": [
        "#2) Labeled LDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmnJotNBUYob",
        "outputId": "97d63985-ad56-4fb9-f903-bd6fb4a7e688"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " T贸picos encontrados:\n",
            "\n",
            " T贸pico 1 (Etiqueta: tecnolog铆a)\n",
            "Los: 0.1631 \n",
            "permiten: 0.0820 \n",
            "r谩pido: 0.0820 \n",
            "m谩s: 0.0820 \n",
            "datos: 0.0820 \n",
            "procesar: 0.0820 \n",
            "artificial: 0.0820 \n",
            "inteligencia: 0.0820 \n",
            "en: 0.0820 \n",
            "avances: 0.0820 \n",
            "\n",
            " T贸pico 2 (Etiqueta: ciencia)\n",
            "a: 0.1161 \n",
            "planeta: 0.0583 \n",
            "complejos: 0.0583 \n",
            "f铆sicos: 0.0583 \n",
            "fen贸menos: 0.0583 \n",
            "simular: 0.0583 \n",
            "ayudan: 0.0583 \n",
            "supercomputadores: 0.0583 \n",
            "Tierra: 0.0583 \n",
            "la: 0.0583 \n",
            "\n",
            " T贸pico 3 (Etiqueta: medicina)\n",
            "nuevo: 0.1380 \n",
            "Un: 0.1380 \n",
            "tratamiento: 0.1380 \n",
            "promete: 0.1380 \n",
            "curar: 0.1380 \n",
            "enfermedades: 0.1380 \n",
            "card铆acas: 0.1380 \n",
            "supercomputadores: 0.0014 \n",
            "ayudan: 0.0014 \n",
            "simular: 0.0014 \n"
          ]
        }
      ],
      "source": [
        "# Crear modelo LLDA\n",
        "llda = tp.PLDAModel()\n",
        "\n",
        "# Datos de ejemplo con sus etiquetas\n",
        "documentos = [\n",
        "    (['tecnolog铆a'], 'Los nuevos avances en inteligencia artificial permiten procesar datos m谩s r谩pido'),\n",
        "    (['ciencia'], 'Los cient铆ficos descubren un nuevo planeta similar a la Tierra'),\n",
        "    (['medicina'], 'Un nuevo tratamiento promete curar enfermedades card铆acas'),\n",
        "    (['tecnolog铆a', 'ciencia'], 'Los supercomputadores ayudan a simular fen贸menos f铆sicos complejos')\n",
        "]\n",
        "\n",
        "# A帽adir documentos al modelo\n",
        "for labels, texto in documentos:\n",
        "    llda.add_doc(words=texto.split(), labels=labels)\n",
        "\n",
        "# Entrenar modelo\n",
        "llda.train(10)\n",
        "\n",
        "# Para cada t贸pico, encontrar su etiqueta m谩s com煤n\n",
        "etiquetas_por_topico = {}\n",
        "for doc_idx, (labels, _) in enumerate(documentos):\n",
        "    doc = llda.docs[doc_idx]\n",
        "    topico_principal = np.argmax(doc.get_topic_dist())\n",
        "    if topico_principal not in etiquetas_por_topico:\n",
        "        etiquetas_por_topico[topico_principal] = []\n",
        "    etiquetas_por_topico[topico_principal].extend(labels)\n",
        "\n",
        "# Mostrar t贸picos con sus etiquetas y palabras\n",
        "print(\"\\n T贸picos encontrados:\")\n",
        "for topico in range(llda.k):\n",
        "    # Encontrar la etiqueta m谩s com煤n para este t贸pico\n",
        "    if topico in etiquetas_por_topico:\n",
        "        etiquetas = etiquetas_por_topico[topico]\n",
        "        etiqueta_mas_comun = max(set(etiquetas), key=etiquetas.count)\n",
        "    else:\n",
        "        etiqueta_mas_comun = \"desconocida\"\n",
        "\n",
        "    print(f\"\\n T贸pico {topico + 1} (Etiqueta: {etiqueta_mas_comun})\")\n",
        "\n",
        "    # Obtener palabras y sus pesos\n",
        "    for palabra, peso in llda.get_topic_words(topico, top_n=10):\n",
        "        barra = \"\" * int(peso * 50)  # Visualizaci贸n del peso\n",
        "        print(f\"{palabra}: {peso:.4f} {barra}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PHfPo4XUdZw"
      },
      "source": [
        "#3) Dynamic Topic Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzyzi80kUgWK",
        "outputId": "26aced74-2b3c-4397-d9d6-8a4ba3d5a8b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Evoluci贸n de t贸picos:\n",
            "\n",
            "\n",
            " T贸pico 1:\n",
            "\n",
            " 2020:\n",
            "de: 0.0754 \n",
            "en: 0.0753 \n",
            "La: 0.0753 \n",
            "global: 0.0752 \n",
            "pandemia: 0.0751 \n",
            "\n",
            " 2021:\n",
            "del: 0.0752 \n",
            "preocupan: 0.0752 \n",
            "diferentes: 0.0751 \n",
            "los: 0.0751 \n",
            "Las: 0.0751 \n",
            "\n",
            " 2022:\n",
            "levantar: 0.1380 \n",
            "Los: 0.1375 \n",
            "La: 0.1375 \n",
            "inmunidad: 0.1375 \n",
            "a: 0.0128 \n",
            "\n",
            " T贸pico 2:\n",
            "\n",
            " 2020:\n",
            "el: 0.0962 \n",
            "en: 0.0544 \n",
            "Los: 0.0543 \n",
            "cient铆ficos: 0.0543 \n",
            "de: 0.0543 \n",
            "\n",
            " 2021:\n",
            "Nuevas: 0.0752 \n",
            "en: 0.0751 \n",
            "avanzan: 0.0751 \n",
            "virus: 0.0751 \n",
            "a: 0.0750 \n",
            "\n",
            " 2022:\n",
            "pa铆ses: 0.0582 \n",
            "comienzan: 0.0581 \n",
            "restricciones: 0.0580 \n",
            "altos: 0.0580 \n",
            "mundial: 0.0580 \n"
          ]
        }
      ],
      "source": [
        "import tomotopy as tp\n",
        "from datetime import datetime\n",
        "\n",
        "# Crear modelo din谩mico (2 t贸picos, 3 periodos de tiempo)\n",
        "dtm = tp.DTModel(k=2, t=3)  # k t贸picos, 3 periodos de tiempo\n",
        "\n",
        "# Datos de ejemplo a trav茅s del tiempo\n",
        "documentos_tiempo = [\n",
        "    # 2020\n",
        "    (2020, 'La pandemia global afecta a millones de personas en todo el mundo'),\n",
        "    (2020, 'Los cient铆ficos trabajan en el desarrollo de vacunas'),\n",
        "    # 2021\n",
        "    (2021, 'Las campa帽as de vacunaci贸n avanzan en diferentes pa铆ses'),\n",
        "    (2021, 'Nuevas variantes del virus preocupan a los expertos'),\n",
        "    # 2022\n",
        "    (2022, 'La poblaci贸n mundial alcanza altos niveles de inmunidad'),\n",
        "    (2022, 'Los pa铆ses comienzan a levantar restricciones sanitarias')\n",
        "]\n",
        "\n",
        "# A帽adir documentos\n",
        "for a帽o, texto in documentos_tiempo:\n",
        "    # Calcular el timestep (0 para 2020, 1 para 2021, 2 para 2022)\n",
        "    timestep = a帽o - 2020\n",
        "    # A帽adir documento con su timestep correspondiente\n",
        "    dtm.add_doc(words=texto.split(), timepoint=timestep)\n",
        "\n",
        "# Entrenar modelo\n",
        "dtm.train(10)\n",
        "\n",
        "# Mostrar evoluci贸n de t贸picos\n",
        "print(\"\\n Evoluci贸n de t贸picos:\\n\")\n",
        "for topic in range(dtm.k):\n",
        "    print(f\"\\n T贸pico {topic + 1}:\")\n",
        "    for t in range(dtm.num_timepoints):\n",
        "        a帽o = 2020 + t\n",
        "        print(f\"\\n {a帽o}:\")\n",
        "        # Mostrar palabras y sus pesos\n",
        "        for palabra, peso in dtm.get_topic_words(topic, timepoint=t, top_n=5):\n",
        "            barra = \"\" * int(peso * 50)\n",
        "            print(f\"{palabra}: {peso:.4f} {barra}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFtGPM1JUts-"
      },
      "source": [
        "#4) Nuevo Documento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTqCE8MZX-_n",
        "outputId": "2052324b-9b0d-43c5-fcfb-d9e5567ebf93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Texto analizado: 'La inteligencia artificial ayuda a los cient铆ficos a desarrollar nuevos medicamentos para curar enfermedades'\n",
            "\n",
            "Distribuci贸n de t贸picos:\n",
            "tecnolog铆a: 37.53% \n",
            "Palabras clave: Los, permiten, r谩pido\n",
            "\n",
            "ciencia: 37.60% \n",
            "Palabras clave: a, planeta, complejos\n",
            "\n",
            "medicina: 24.87% \n",
            "Palabras clave: nuevo, Un, tratamiento\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Primero creamos un mapeo de t贸picos a etiquetas basado en el entrenamiento\n",
        "def crear_mapeo_topicos_etiquetas(modelo, documentos_entrenamiento):\n",
        "    topico_a_etiqueta = {}\n",
        "    for doc_idx, (etiquetas, _) in enumerate(documentos_entrenamiento):\n",
        "        doc = modelo.docs[doc_idx]\n",
        "        # Obtener el t贸pico dominante para este documento\n",
        "        topico_principal = np.argmax(doc.get_topic_dist())\n",
        "        if topico_principal not in topico_a_etiqueta:\n",
        "            topico_a_etiqueta[topico_principal] = etiquetas[0]  # Tomamos la primera etiqueta\n",
        "    return topico_a_etiqueta\n",
        "\n",
        "# Funci贸n  para analizar documentos\n",
        "def analizar_documento(texto, modelo, mapeo_topicos):\n",
        "    # Preprocesar el texto\n",
        "    palabras = texto.split()\n",
        "\n",
        "    # Inferir t贸picos\n",
        "    doc = modelo.make_doc(palabras)\n",
        "    topicos = modelo.infer(doc)[0]\n",
        "\n",
        "    print(f\"\\nTexto analizado: '{texto}'\")\n",
        "    print(\"\\nDistribuci贸n de t贸picos:\")\n",
        "\n",
        "    # Mostrar distribuci贸n para cada t贸pico\n",
        "    for topico_idx, prob in enumerate(topicos):\n",
        "        etiqueta = mapeo_topicos.get(topico_idx, f\"T贸pico {topico_idx+1}\")\n",
        "        barra = \"\" * int(prob * 50)\n",
        "        print(f\"{etiqueta}: {prob:.2%} {barra}\")\n",
        "        # Mostrar palabras m谩s relevantes del t贸pico\n",
        "        palabras = [word for word, _ in modelo.get_topic_words(topico_idx, top_n=3)]\n",
        "        print(f\"Palabras clave: {', '.join(palabras)}\\n\")\n",
        "\n",
        "# Crear el mapeo de t贸picos a etiquetas\n",
        "mapeo_topicos = crear_mapeo_topicos_etiquetas(llda, documentos)\n",
        "\n",
        "# Ejemplo de uso\n",
        "nuevo_texto = \"La inteligencia artificial ayuda a los cient铆ficos a desarrollar nuevos medicamentos para curar enfermedades\"\n",
        "analizar_documento(nuevo_texto, llda, mapeo_topicos)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMuncR3MzkJYulqPlD8PzrM",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
