{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cbadenes/curso-pln/blob/main/notebooks/04_Extensiones_LDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebFZnbzaURA9"
      },
      "source": [
        "#1)  Instalación y dependencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzWAIBHtUOBD",
        "outputId": "d4906b7d-2dea-491c-e4e5-270a88e1d29b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tomotopy in /usr/local/lib/python3.11/dist-packages (0.13.0)\n",
            "Requirement already satisfied: numpy<2,>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tomotopy) (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "#!pip install numpy==1.26.4 tomotopy==0.13.0 pandas==2.2.2\n",
        "!pip install --upgrade tomotopy\n",
        "\n",
        "import tomotopy as tp\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-luCInCqUWvA"
      },
      "source": [
        "#2) Labeled LDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmnJotNBUYob",
        "outputId": "1f1347b3-06bf-4603-ca2b-5defb20cda83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Tópicos encontrados:\n",
            "\n",
            "📌 Tópico 1 (Etiqueta: tecnología)\n",
            "permiten: 0.0892 ████\n",
            "Los: 0.0892 ████\n",
            "rápido: 0.0892 ████\n",
            "más: 0.0892 ████\n",
            "datos: 0.0892 ████\n",
            "procesar: 0.0892 ████\n",
            "artificial: 0.0892 ████\n",
            "inteligencia: 0.0892 ████\n",
            "en: 0.0892 ████\n",
            "avances: 0.0892 ████\n",
            "\n",
            "📌 Tópico 2 (Etiqueta: ciencia)\n",
            "a: 0.1097 █████\n",
            "Los: 0.1097 █████\n",
            "planeta: 0.0551 ██\n",
            "complejos: 0.0551 ██\n",
            "físicos: 0.0551 ██\n",
            "fenómenos: 0.0551 ██\n",
            "simular: 0.0551 ██\n",
            "ayudan: 0.0551 ██\n",
            "supercomputadores: 0.0551 ██\n",
            "Tierra: 0.0551 ██\n",
            "\n",
            "📌 Tópico 3 (Etiqueta: medicina)\n",
            "nuevo: 0.1380 ██████\n",
            "Un: 0.1380 ██████\n",
            "tratamiento: 0.1380 ██████\n",
            "promete: 0.1380 ██████\n",
            "curar: 0.1380 ██████\n",
            "enfermedades: 0.1380 ██████\n",
            "cardíacas: 0.1380 ██████\n",
            "supercomputadores: 0.0014 \n",
            "ayudan: 0.0014 \n",
            "simular: 0.0014 \n"
          ]
        }
      ],
      "source": [
        "# Crear modelo LLDA\n",
        "llda = tp.PLDAModel()\n",
        "\n",
        "# Datos de ejemplo con sus etiquetas\n",
        "documentos = [\n",
        "    (['tecnología'], 'Los nuevos avances en inteligencia artificial permiten procesar datos más rápido'),\n",
        "    (['ciencia'], 'Los científicos descubren un nuevo planeta similar a la Tierra'),\n",
        "    (['medicina'], 'Un nuevo tratamiento promete curar enfermedades cardíacas'),\n",
        "    (['tecnología', 'ciencia'], 'Los supercomputadores ayudan a simular fenómenos físicos complejos')\n",
        "]\n",
        "\n",
        "# Añadir documentos al modelo\n",
        "for labels, texto in documentos:\n",
        "    llda.add_doc(words=texto.split(), labels=labels)\n",
        "\n",
        "# Entrenar modelo\n",
        "llda.train(10)\n",
        "\n",
        "# Para cada tópico, encontrar su etiqueta más común\n",
        "etiquetas_por_topico = {}\n",
        "for doc_idx, (labels, _) in enumerate(documentos):\n",
        "    doc = llda.docs[doc_idx]\n",
        "    topico_principal = np.argmax(doc.get_topic_dist())\n",
        "    if topico_principal not in etiquetas_por_topico:\n",
        "        etiquetas_por_topico[topico_principal] = []\n",
        "    etiquetas_por_topico[topico_principal].extend(labels)\n",
        "\n",
        "# Mostrar tópicos con sus etiquetas y palabras\n",
        "print(\"\\n🔍 Tópicos encontrados:\")\n",
        "for topico in range(llda.k):\n",
        "    # Encontrar la etiqueta más común para este tópico\n",
        "    if topico in etiquetas_por_topico:\n",
        "        etiquetas = etiquetas_por_topico[topico]\n",
        "        etiqueta_mas_comun = max(set(etiquetas), key=etiquetas.count)\n",
        "    else:\n",
        "        etiqueta_mas_comun = \"desconocida\"\n",
        "\n",
        "    print(f\"\\n📌 Tópico {topico + 1} (Etiqueta: {etiqueta_mas_comun})\")\n",
        "\n",
        "    # Obtener palabras y sus pesos\n",
        "    for palabra, peso in llda.get_topic_words(topico, top_n=10):\n",
        "        barra = \"█\" * int(peso * 50)  # Visualización del peso\n",
        "        print(f\"{palabra}: {peso:.4f} {barra}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PHfPo4XUdZw"
      },
      "source": [
        "#3) Dynamic Topic Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzyzi80kUgWK",
        "outputId": "c35655da-1632-45aa-dad7-32361d2b508c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Evolución de tópicos:\n",
            "\n",
            "\n",
            " Tópico 1:\n",
            "\n",
            " 2020:\n",
            "de: 0.1377 ██████\n",
            "La: 0.0754 ███\n",
            "vacunas: 0.0753 ███\n",
            "todo: 0.0752 ███\n",
            "millones: 0.0750 ███\n",
            "\n",
            " 2021:\n",
            "países: 0.0545 ██\n",
            "variantes: 0.0542 ██\n",
            "Las: 0.0542 ██\n",
            "de: 0.0542 ██\n",
            "diferentes: 0.0542 ██\n",
            "\n",
            " 2022:\n",
            "comienzan: 0.0683 ███\n",
            "sanitarias: 0.0683 ███\n",
            "mundial: 0.0683 ███\n",
            "de: 0.0682 ███\n",
            "inmunidad: 0.0682 ███\n",
            "\n",
            " Tópico 2:\n",
            "\n",
            " 2020:\n",
            "el: 0.0958 ████\n",
            "mundo: 0.0544 ██\n",
            "trabajan: 0.0544 ██\n",
            "Los: 0.0543 ██\n",
            "afecta: 0.0543 ██\n",
            "\n",
            " 2021:\n",
            "Nuevas: 0.1379 ██████\n",
            "del: 0.1377 ██████\n",
            "campañas: 0.1376 ██████\n",
            "avanzan: 0.1376 ██████\n",
            "de: 0.0129 \n",
            "\n",
            " 2022:\n",
            "a: 0.0964 ████\n",
            "restricciones: 0.0960 ████\n",
            "levantar: 0.0960 ████\n",
            "población: 0.0960 ████\n",
            "La: 0.0958 ████\n"
          ]
        }
      ],
      "source": [
        "import tomotopy as tp\n",
        "from datetime import datetime\n",
        "\n",
        "# Crear modelo dinámico (2 tópicos, 3 periodos de tiempo)\n",
        "dtm = tp.DTModel(k=2, t=3)  # k tópicos, 3 periodos de tiempo\n",
        "\n",
        "# Datos de ejemplo a través del tiempo\n",
        "documentos_tiempo = [\n",
        "    # 2020\n",
        "    (2020, 'La pandemia global afecta a millones de personas en todo el mundo'),\n",
        "    (2020, 'Los científicos trabajan en el desarrollo de vacunas'),\n",
        "    # 2021\n",
        "    (2021, 'Las campañas de vacunación avanzan en diferentes países'),\n",
        "    (2021, 'Nuevas variantes del virus preocupan a los expertos'),\n",
        "    # 2022\n",
        "    (2022, 'La población mundial alcanza altos niveles de inmunidad'),\n",
        "    (2022, 'Los países comienzan a levantar restricciones sanitarias')\n",
        "]\n",
        "\n",
        "# Añadir documentos\n",
        "for año, texto in documentos_tiempo:\n",
        "    # Calcular el timestep (0 para 2020, 1 para 2021, 2 para 2022)\n",
        "    timestep = año - 2020\n",
        "    # Añadir documento con su timestep correspondiente\n",
        "    dtm.add_doc(words=texto.split(), timepoint=timestep)\n",
        "\n",
        "# Entrenar modelo\n",
        "dtm.train(10)\n",
        "\n",
        "# Mostrar evolución de tópicos\n",
        "print(\"\\n Evolución de tópicos:\\n\")\n",
        "for topic in range(dtm.k):\n",
        "    print(f\"\\n Tópico {topic + 1}:\")\n",
        "    for t in range(dtm.num_timepoints):\n",
        "        año = 2020 + t\n",
        "        print(f\"\\n {año}:\")\n",
        "        # Mostrar palabras y sus pesos\n",
        "        for palabra, peso in dtm.get_topic_words(topic, timepoint=t, top_n=5):\n",
        "            barra = \"█\" * int(peso * 50)\n",
        "            print(f\"{palabra}: {peso:.4f} {barra}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFtGPM1JUts-"
      },
      "source": [
        "#4) Nuevo Documento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTqCE8MZX-_n",
        "outputId": "45dfec10-f60f-46ca-e5f0-2d49807df665"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Texto analizado: 'La inteligencia artificial ayuda a los científicos a desarrollar nuevos medicamentos para curar enfermedades'\n",
            "\n",
            "Distribución de tópicos:\n",
            "tecnología: 37.40% ▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓\n",
            "Palabras clave: permiten, Los, rápido\n",
            "\n",
            "ciencia: 37.60% ▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓\n",
            "Palabras clave: a, Los, planeta\n",
            "\n",
            "medicina: 25.00% ▓▓▓▓▓▓▓▓▓▓▓▓\n",
            "Palabras clave: nuevo, Un, tratamiento\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Primero creamos un mapeo de tópicos a etiquetas basado en el entrenamiento\n",
        "def crear_mapeo_topicos_etiquetas(modelo, documentos_entrenamiento):\n",
        "    topico_a_etiqueta = {}\n",
        "    for doc_idx, (etiquetas, _) in enumerate(documentos_entrenamiento):\n",
        "        doc = modelo.docs[doc_idx]\n",
        "        # Obtener el tópico dominante para este documento\n",
        "        topico_principal = np.argmax(doc.get_topic_dist())\n",
        "        if topico_principal not in topico_a_etiqueta:\n",
        "            topico_a_etiqueta[topico_principal] = etiquetas[0]  # Tomamos la primera etiqueta\n",
        "    return topico_a_etiqueta\n",
        "\n",
        "# Función  para analizar documentos\n",
        "def analizar_documento(texto, modelo, mapeo_topicos):\n",
        "    # Preprocesar el texto\n",
        "    palabras = texto.split()\n",
        "\n",
        "    # Inferir tópicos\n",
        "    doc = modelo.make_doc(palabras)\n",
        "    topicos = modelo.infer(doc)[0]\n",
        "\n",
        "    print(f\"\\nTexto analizado: '{texto}'\")\n",
        "    print(\"\\nDistribución de tópicos:\")\n",
        "\n",
        "    # Mostrar distribución para cada tópico\n",
        "    for topico_idx, prob in enumerate(topicos):\n",
        "        etiqueta = mapeo_topicos.get(topico_idx, f\"Tópico {topico_idx+1}\")\n",
        "        barra = \"▓\" * int(prob * 50)\n",
        "        print(f\"{etiqueta}: {prob:.2%} {barra}\")\n",
        "        # Mostrar palabras más relevantes del tópico\n",
        "        palabras = [word for word, _ in modelo.get_topic_words(topico_idx, top_n=3)]\n",
        "        print(f\"Palabras clave: {', '.join(palabras)}\\n\")\n",
        "\n",
        "# Crear el mapeo de tópicos a etiquetas\n",
        "mapeo_topicos = crear_mapeo_topicos_etiquetas(llda, documentos)\n",
        "\n",
        "# Ejemplo de uso\n",
        "nuevo_texto = \"La inteligencia artificial ayuda a los científicos a desarrollar nuevos medicamentos para curar enfermedades\"\n",
        "analizar_documento(nuevo_texto, llda, mapeo_topicos)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}