{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNvC3ZhPYYYkL7jxZroq3PJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cbadenes/curso-pln/blob/main/notebooks/03_embeddings_sherlock_holmes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embeddings de Palabras a partir de libros de Sherlock Holmes\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pgX4RcCCEzfb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0) Preparación de librerías\n"
      ],
      "metadata": {
        "id": "yPjlrAJ__QPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.26.4 scipy==1.13.1 gensim==4.3.3 spacy==3.7.5"
      ],
      "metadata": {
        "id": "u7QUkGIB_MKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) Carga de Datos\n",
        "\n",
        "Carga libros publicados en Project Gutenberg y elimina el header/footer:"
      ],
      "metadata": {
        "id": "CT5uuELv_Pul"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xr89zm_uEldQ",
        "outputId": "d106f9d6-7820-4e8b-e5af-21f401273c6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cargando texto desde: https://www.gutenberg.org/files/1661/1661-0.txt ..\n",
            "Cargando texto desde: https://www.gutenberg.org/files/108/108-0.txt ..\n",
            "Cargando texto desde: https://www.gutenberg.org/files/2097/2097-0.txt ..\n",
            "Cargando texto desde: https://www.gutenberg.org/files/244/244-0.txt ..\n",
            "Texto cargado: 1742150 caracteres\n"
          ]
        }
      ],
      "source": [
        "import urllib.request\n",
        "from pathlib import Path\n",
        "\n",
        "def load_gutenberg_text(url):\n",
        "    print(\"Cargando texto desde:\", url, \"..\")\n",
        "    response = urllib.request.urlopen(url)\n",
        "    raw = response.read().decode('utf-8')\n",
        "\n",
        "    # Encontrar el inicio y fin del contenido real (eliminar header/footer de Gutenberg)\n",
        "    start = raw.find(\"*** START OF THE PROJECT GUTENBERG\")\n",
        "    start = raw.find(\"\\n\", start) + 1\n",
        "    end = raw.find(\"*** END OF THE PROJECT GUTENBERG\")\n",
        "\n",
        "    return raw[start:end]\n",
        "\n",
        "# URLs de los libros en Project Gutenberg\n",
        "urls = [\n",
        "    \"https://www.gutenberg.org/files/1661/1661-0.txt\",    # The Adventures of Sherlock Holmes\n",
        "    \"https://www.gutenberg.org/files/108/108-0.txt\",      # The Return of Sherlock Holmes\n",
        "    \"https://www.gutenberg.org/files/2097/2097-0.txt\",    # The Hound of the Baskervilles\n",
        "    \"https://www.gutenberg.org/files/244/244-0.txt\"       # A Study in Scarlet\n",
        "]\n",
        "\n",
        "# Carga y guarda el texto\n",
        "text = \" \"\n",
        "for url in urls:\n",
        "  book_text = load_gutenberg_text(url)\n",
        "  text += book_text\n",
        "\n",
        "\n",
        "print(\"Texto cargado:\", len(text), \"caracteres\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) Preprocesamiento\n",
        "\n",
        "Tokeniza y limpia el texto:\n",
        "* Convierte a minúsculas\n",
        "* Elimina tokens que no son palabras"
      ],
      "metadata": {
        "id": "aEFtcjHpFBD0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.lang.en import English\n",
        "\n",
        "# Inicializar spaCy (solo tokenizador para velocidad)\n",
        "nlp = English(disable=['tagger','parser','ner'])\n",
        "\n",
        "def tokenize(text):\n",
        "    doc = nlp(text)\n",
        "    return [token.text.lower() for token in doc\n",
        "            if token.text.strip() and not token.is_punct]\n",
        "\n",
        "# Dividir en oraciones y tokenizar\n",
        "corpus_sentences = []\n",
        "for line in text.split('\\n'):\n",
        "    if line.strip():  # ignorar líneas vacías\n",
        "        tokens = tokenize(line)\n",
        "        if tokens:  # ignorar líneas sin tokens válidos\n",
        "            corpus_sentences.append(tokens)\n",
        "\n",
        "print(\"Total de oraciones procesadas:\", len(corpus_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOY6GToqFB8G",
        "outputId": "d0487378-b24e-4c1f-e895-6859f14fa7e2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de oraciones procesadas: 27683\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3) Modelo Word2Vec\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "NAXkjJtYFF0Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3.1) Entrenamiento"
      ],
      "metadata": {
        "id": "qz6fz_DXFX0v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "w2v_model = Word2Vec(sentences=corpus_sentences,\n",
        "                    vector_size=300,      # Dimensión del vector (300)\n",
        "                    window=8,             # Ventana más amplia para capturar más contexto (8)\n",
        "                    min_count=2,          # Filtrar palabras poco frecuentes (5)\n",
        "                    workers=4,\n",
        "                    sg=1,                 # Usar Skip-gram\n",
        "                    epochs= 30,           # Más ciclos de entrenamiento\n",
        "                    negative= 15,         # Tamaño de Muestra Negativa (Negative sampling)\n",
        "                    alpha= 0.025,         # Learning rate inicial\n",
        "                    min_alpha= 0.0001     # Learning rate final\n",
        "                  )"
      ],
      "metadata": {
        "id": "-E69AoT3FLt9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Guardar modelos"
      ],
      "metadata": {
        "id": "lUuvM3a_FdVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.save(\"sherlock_w2v.model\")"
      ],
      "metadata": {
        "id": "CcwtMCPHFSmx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2) Análisis de Similitudes"
      ],
      "metadata": {
        "id": "Alaz2yIXFV2J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cargar vectores"
      ],
      "metadata": {
        "id": "-Af8SyvvFg24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_vectors = w2v_model.wv\n",
        "\n",
        "print(\"\\nEstadísticas del modelo:\")\n",
        "print(\"Dimensión de los vectores:\", w2v_vectors.vector_size)\n",
        "print(\"Número de palabras (Word2Vec):\", len(w2v_vectors.index_to_key))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yLfuYjtFWWr",
        "outputId": "15f07f72-0d5a-4acb-89f5-8b4d25df1478"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Estadísticas del modelo:\n",
            "Dimensión de los vectores: 300\n",
            "Número de palabras (Word2Vec): 8416\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nPalabras más similares a 'holmes' (Word2Vec):\")\n",
        "print(w2v_vectors.most_similar('holmes'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyZz7D9DFk5l",
        "outputId": "db3e6fb1-f15c-4a61-aaa9-de163c29d266"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Palabras más similares a 'holmes' (Word2Vec):\n",
            "[('sherlock', 0.5204015374183655), ('demurely', 0.4592164158821106), ('mr', 0.4341519773006439), ('cheerily', 0.43188294768333435), ('approvingly', 0.4205712080001831), ('gleefully', 0.4183337986469269), ('involuntarily', 0.41294097900390625), ('bungler', 0.40235358476638794), ('compliment', 0.40162819623947144), ('motioning', 0.4008224606513977)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nPalabras más similares a 'crime' (Word2Vec):\")\n",
        "print(w2v_vectors.most_similar('crime'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLq7S5YvFqXC",
        "outputId": "0b07792b-74fc-4468-8964-fec6e283db2c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Palabras más similares a 'crime' (Word2Vec):\n",
            "[('committed', 0.5234676599502563), ('literature', 0.47155189514160156), ('deliberate', 0.46535801887512207), ('featureless', 0.4565415382385254), ('logic', 0.442795991897583), ('records', 0.4420148432254791), ('perpetrator', 0.4353950023651123), ('talent', 0.43511196970939636), ('insane', 0.4232688248157501), ('detect', 0.42240411043167114)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nSimilitud entre 'crime' y 'art':\")\n",
        "print(\"Word2Vec:\", w2v_vectors.similarity('crime', 'art'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_vPFl2EFsUo",
        "outputId": "fcd30ba0-433b-45c1-cd6d-ac5e40bda2f4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Similitud entre 'crime' y 'art':\n",
            "Word2Vec: 0.2433517\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3) Palabras fuera de vocabulario"
      ],
      "metadata": {
        "id": "SEwj5kfhFu3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nPrueba con palabra fuera de vocabulario:\")\n",
        "try:\n",
        "    print(\"Word2Vec - Similares a 'investigador':\")\n",
        "    print(w2v_vectors.most_similar('investigador'))\n",
        "except KeyError:\n",
        "    print(\"Word2Vec no puede manejar palabras fuera de vocabulario\")"
      ],
      "metadata": {
        "id": "SMxXTQUQFwvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.4) Analogías"
      ],
      "metadata": {
        "id": "G-wbbEIyF5qc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nAnalogías (Word2Vec):\")\n",
        "result = w2v_vectors.most_similar(positive=['watson', 'crime'],\n",
        "                                negative=['holmes'])\n",
        "print(\"watson:holmes como crime:?\")\n",
        "print(result)"
      ],
      "metadata": {
        "id": "vmtgbjYoF3La"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4) Modelo FastText\n"
      ],
      "metadata": {
        "id": "bBvI1CQgQGLx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4.1) Entrenamiento"
      ],
      "metadata": {
        "id": "xGyf8y68QhID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import FastText\n",
        "ft_model = FastText(sentences=corpus_sentences,\n",
        "                   vector_size=300,    # Aumentar dimensionalidad (300)\n",
        "                   window=8,           # Ventana más amplia para capturar más contexto (8)\n",
        "                   min_count=2,        # Mantener min_count bajo para capturar más variantes\n",
        "                   workers=4,\n",
        "                   sg=1,               # Skip-gram para mejor calidad\n",
        "                   min_n=2,            # Tamaño mínimo de n-gramas\n",
        "                   max_n=6,            # Tamaño máximo de n-gramas (aumentado para capturar más patrones)\n",
        "                   epochs=30,          # Más ciclos de entrenamiento (30)\n",
        "                   word_ngrams=1,      # Habilitar n-gramas de palabras\n",
        "                   negative=15,        # Más muestras negativas\n",
        "                   alpha=0.025,        # Learning rate inicial\n",
        "                   min_alpha=0.0001    # Learning rate final\n",
        "              )"
      ],
      "metadata": {
        "id": "qHLPLzC6FNtk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Almacenamiento del modelo:"
      ],
      "metadata": {
        "id": "WrD-xvupRPYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ft_model.save(\"sherlock_ft.model\")"
      ],
      "metadata": {
        "id": "3xwAe7HORRGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2) Análisis de Similitudes"
      ],
      "metadata": {
        "id": "PjIe1rgrRfB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ft_vectors = ft_model.wv\n",
        "\n",
        "print(\"\\nEstadísticas del modelo:\")\n",
        "print(\"Dimensión de los vectores:\", ft_vectors.vector_size)\n",
        "print(\"Número de palabras (FastText):\", len(ft_vectors.index_to_key))"
      ],
      "metadata": {
        "id": "UWm-jwakRhXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nPalabras más similares a 'holmes' (FastText):\")\n",
        "print(ft_vectors.most_similar('holmes'))"
      ],
      "metadata": {
        "id": "iqOEszGBSJfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nPalabras más similares a 'crime' (Word2Vec):\")\n",
        "print(ft_vectors.most_similar('crime'))"
      ],
      "metadata": {
        "id": "Xi21tk9tSP4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nSimilitud entre 'crime' y 'art':\")\n",
        "print(\"FastText:\", ft_vectors.similarity('crime', 'art'))"
      ],
      "metadata": {
        "id": "m83OuWC6SVS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4.3) Palabras fuera del vocabulario"
      ],
      "metadata": {
        "id": "kH2SCcT3SiAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nPrueba con palabra fuera de vocabulario:\")\n",
        "\n",
        "print(\"\\nFastText - Similares a 'investigador':\")\n",
        "print(ft_vectors.most_similar('investigador'))  # FastText puede generar vectores para palabras nuevas\n"
      ],
      "metadata": {
        "id": "RNaWVvPMSkfd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}